---
title: '[ONGOING] Going to the gym with MLIR: Linear register allocation for ... a stackless virtual machine?'
date: 8888-08-08
recap: "Jasmine plans out register allocation for the DEX recompiler."
---

[Please, please, please](https://www.youtube.com/watch?v=zAgVtzhjfCA&ab_channel=SabrinaCarpenter-Topic) don't read
it now. It's unfinished, and I'm not sure if it'll go into impl or design doc :)

## Prologue
Hi everyone, I hope everybody's been great :) I hope you like my last report for my graduate class [here](https://badumbatish.github.io/posts/going_to_mlir_gym_1). This article is also related to the same project. It
discusses the
SSA linear scan
register
allocation algorithm and the steps taken to implement it.

Just like the last MLIR report post, I also include a supporting section (**SS**) right before the introduction for
unfamiliar
reader in the compiler space.

Without reading the SS, I assume interested readers are familiar with some basic middle-end IR concepts (e.g $\phi$
notation, liveness analysis, loops).

With reading the SS, there is some context from the last report's [SS](https://badumbatish.github.io/posts/going_to_mlir_gym_1#reader-supporting-section) that I think would be helpful.

And as is tradition, I also wanna share a [song](https://www.youtube.com/watch?v=5HFyoxqUi0g&ab_channel=CROWONHYENAS) for
you to listen to while reading. Initially it was between this song and [that](https://www.youtube.com/watch?v=eW6f7mEXfPQ&ab_channel=HipHopDXAsia) song. What can I say? I guess this is a long form way to say I want you to listen to
both :)

I hope everybody enjoys :)


## Reader supporting section
- Dominance: In a CFG, with the entry basic block $BB_0$ and any two basic block A and B, if all paths from
$BB_0$ to B goes through A, then A is said to dominate B. The notation for dominance is A
$\gg$ B and every node is said to dominate itself.

- Dataflow analysis: Abstractly, dataflow analysis is a way to understand how data moves and changes throughout a
computer program.
It helps us track what happens to different values (like variables) as the program runs from start to finish.

For example, when [reaching definition](https://en.wikipedia.org/wiki/Reaching_definition) is
run, the compiler can detect if some variable is possibly uninitialized and warn us if such cases appear:
```rust
// Just an example for reaching definition.
fn reaching_def_example(condition: bool) {
    let x: i32; // x is declared but not initialized

    if condition { // if this `if` condition is `false`,
       x = 5;      // `x` is not initialized
    }

    println!("{}", x); // Warning: x might be uninitialized
                      // if condition is false
}
```

- Loop header: In hand with dominance, a block is said to be a loop header if it dominates one of its
predecessors (a block that points to it). Knowing what a loop header is, and later identifying it would be of great
help in
our live intervals (of our linear register allocator) construction. As in the paper by Wimmer and Franz, their live
intervals construction bypasses the dataflow analysis cost itself, simply on the concept of dominance and loop header.

Before heading further, let's look at an example for the two concepts.

In this control flow graph, A dominates every BB, including itself.
B dominates D; even though there is a path from
D to B, it must have first passed from B first. Since B dominates its predecessor, B is a loop header; hence,
there is a loop :)

D is:
![dominance_mlir_gym_2.svg](/blogs/dominance_mlir_gym_2.svg)

- Live interval and Live ranges pre-notes: Different papers derive the meaning of a live range differently. For example,
in Engineering a
Compiler 2nd Edition pg. 690, live range is a closed set of pairs of use and def locations. In Mössenböck &
Pfeiffer, the roughly same definition is dedicated to `live intervals`, leaving the meaning of `range` to just mean
a pair of `use` and `def`. I chose to follow the definition laid out by Mössenböck & Pfeiffer where a live interval
contains an ordered list of live ranges. [todo, add some example here, or the next two section?]

For example:
```
// Add an example here pleaseeeeeeeee >,<

```
Overall, the concepts were born to ease the job of register allocators. If some variables are not live anymore
(since their definitions), their registers can be reused for another variable instead. In this view, contention for a
register (a scarce resource)
between some variables can instead be seen as the intersection (or lack thereof) between different live ranges. In
this effect, at the register allocation phase, the compiler effective translates the tradition SSA variable naming
scheme into a set of live intervals.

Hopefully, after
reading the two (closely related) definitions and seeing how they're defined to solve the same problem, we've cleared
up the
confusion.


## Introduction

Register allocation is an important aspect in the compiler construction phase.
Registers being the fastest
(but most limited) in the memory hierarchy, the compiler's register allocator must be strategic about this
resource, more usages in registers instead of the stack means reduced latency and
improved execution speed.

In the case of our recompiler, the main motivation related to obfuscation. [Edu](https://farena.in/)'s employer,
[Quarkslab](https://www.quarkslab.com/) is interested in applying obfuscation method to DEX files. With the methods
generating a lot of virtual registers, there were concerns about it exceeding the limit of $2^{16} = 65,536$ virtual
registers. In this case, the linear register allocation project helps bring down the number of virtual registers under
the limit (of course they can just run less obfuscation hahahah).

This article then draws the learning mainly from three sources: the text book Engineer a Compiler, and two papers
from Mössenböck & Pfeiffer [MP02] and Wimmer & Franz [WF10].

Personally, this is also another opportunity for me to improve my compiler arsenal. Some undergraduate compiler
classes leave this part out or only as part of a pen and paper exercise; knowing how to perform register allocation
(and writing about it)
would be a big push in the direction.

All discussed concepts are driven from the links in the resources section.

## Planning

### Differences
We're planning to improve the lowering of MjolnIR to smali. What this means is that instead of lowering directly
from SSA variables to virtual registers with
`template<class Aspect> class SmaliCounter{:cpp}`, we lower indirectly with our register
allocation, first translating them into the namespace of live intervals first, then down to virtual registers.

More specifically, we'll :

- Produce live intervals from ssa values and their uses and defs.
- Optionally merge `compatible` live intervals together (the process is called coalescing).
- Lower down to virtual registers.

This new process introduces new stages that are clearly described and compared through this diagram.

[todo add mermaid here]

### Steps

To say that linear register allocation simply comprises 3 steps is a simplification. The three big steps eventually
break down into substeps when a reader starts asking these questions of the sort: Where and how do
we get our live intervals? How do we map SSA value to a said interval? What mechanics helps us merge `compatible`? How is
MLIR helping here? We'll
- First discuss the problem of $\phi$ in the context of live intervals.
- Number the mlir operation via the topological ordering of basic blocks.
- Construct our live intervals.
- Coalesce
- Translate to virtual registers, during this time we might split intervals to produce what is called live holes.

It is important to note that although I follow the MP02 paper, some recaps for WF10 will also be noted.

### Phis in register allocation

The nuisance of $\phi$s is rooted in the idea that if two basic blocks $B_1$ and $B_2$ with their respective SSA
variables $b_1$ and $b_2$ both connect at basic block $C$ with the $\phi_{c}$, the two SSA variables (and the $\phi$)
should really be in the same register, right??

In this context, different papers (MP02 and WF10) handle this problem differently.

traverses the CFG and add them to this

T
todo: discuss Brock and then wimmer.



### Live intervals

In linear scan register allocation, we first flatten the CFG into a list of live intervals first. In the
Wimmer and Franz paper, this is achieved with an ordered list based on the BB's dominance. I should also note here that
ordered (in layperson terms)
means that if
block A arrives before block B, then block B cannot dominate block A.

Since the topological ordering of the graph naturally lends itself to a dominance ordered list, MLIR itself shows
its definition for `mlir::getBlocksSortedByDominance{:cpp}` as reverse-post-order DFS:

```cpp
SetVector<Block *> mlir::getBlocksSortedByDominance(Region &region) {
    // For each block that has not been visited yet (i.e. that has no
    // predecessors), add it to the list as well as its successors.
    SetVector<Block *> blocks;
    for (Block &b : region) {
         if (blocks.count(&b) == 0) {
               llvm::ReversePostOrderTraversal<Block *> traversal(&b);
               blocks.insert(traversal.begin(), traversal.end());
         }
    }
    assert(blocks.size() == region.getBlocks().size() &&
          "some blocks are not sorted");

    return blocks;
}
```

At this point, we've gotten our hands on the block list. But Wimmer and Franz introduce a stronger condition: all
blocks belonging to the same loop must be continuous and that "TODO".

Personally, I think the API provided by MLIR won't
satisfy
the condition. Given A is the header of a loop, that either goes to B* (the loop) or breaks out to C, since B* loops
back to A. Then, if the list ordering is A-C-B*, the live intervals of C interferes with the loop's live intervals,
forcing us to take C into the equation and degrade the loop's register performance.

Thus the next step is to make sure that a loop header should always be followed by its loop body.

- todo: need to also detect loop
https://pages.cs.wisc.edu/~fischer/cs701.f14/finding.loops.html

The procedure will be

- Linearize the blocks of CFG based on dominance, with blocks in the loop being the same.

- Construct the live ranges (with live holes).

- Construct the

#### Algorithm
### Topo sort with loop continuity
```cpp

auto topo_blocks = mlir get blocks sorted by dom;
auto order = map that maps order to block
auto result = {};
for each block b in topo_block
    if already in result
        continue
    else
        if exist a back edge from e to b


```
### Building live intervals

In building the live intervals, we first start with the numbering of operations.


TODO: say how phi's hard to handle
```cpp
using LRStart = uint32_t;
using LREnd= uint32_t;
using LiveRange = std::pair<LRStart, LREnd>; // From above description
DenseMap<Value, Vector<LiveRange>> build_intervals(todo: type of set vector block from topo sort and correct loop
continuity) {
    // TODO: i know my ass will need the smali counter again soon. Maybe split the function here.

    // TODO: We get the value from the operand like this

    for b in blocks:
        for op in b:
            if v = op.getValue() then
                smali_counter.getCounter(v);

    // todo: we do this because although we visualize ssa as having an inherent counter, it is not visible in the
mlir api
}
```
## Obstacles

## Resources

### Papers
- MP02 - [Linear Scan Register Allocation in the Context of SSA Form and Register Constraints](https://link.springer.
com/content/pdf/10.1007/3-540-45937-5_17.pdf) - Hanspeter Mössenböck and Michael Pfeiffer.
- WF10 [Linear Scan Register Allocation on SSA Form](http://www.christianwimmer.at/Publications/Wimmer10a/Wimmer10a.
pdf) -
Christian Wimmer and Michael Franz.
- [Linear Scan Register Allocation](https://web.cs.ucla.edu/~palsberg/course/cs132/linearscan.pdf) - Massimiliano
Poletto and Vivek Sarkar.
### Textbooks

- [Engineering a Compiler](https://www.goodreads.com/book/show/60277251-engineering-a-compiler) - Keith D. Cooper and Linda Torczon.

### AI tools

Hahahaha you're really funny.